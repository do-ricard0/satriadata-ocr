{
  "cells": [
    {
      "id": "017c680f-7a7d-4bfb-8a57-217119b3a22c",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "ebf12e0b-785b-43d9-925c-baee64dba893"
        },
        "ExecuteTime": {
          "end_time": "2023-06-29T17:40:27.677168+00:00",
          "start_time": "2023-06-29T17:37:26.646727+00:00"
        }
      },
      "execution_count": null,
      "source": "!pip install opencv-python-headless tensorflow torch torchvision",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "noteable": {
          "output_collection_id": "02e9eca9-84f8-403c-babe-a9872e06a815"
        },
        "ExecuteTime": {
          "end_time": "2023-06-29T17:41:25.916578+00:00",
          "start_time": "2023-06-29T17:41:24.802530+00:00"
        },
        "datalink": {
          "857040ec-bd5f-42fd-9684-01103dc1e807": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 4,
              "orig_num_rows": 800,
              "orig_size_bytes": 32000,
              "truncated_num_cols": 4,
              "truncated_num_rows": 800,
              "truncated_size_bytes": 32000,
              "truncated_string_columns": []
            },
            "display_id": "857040ec-bd5f-42fd-9684-01103dc1e807",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-06-29T17:41:25.752610",
            "user_variable_name": "train_data",
            "variable_name": "train_data"
          }
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Load the dataset\n",
        "data_train_path = 'data/train/DataTrain.csv'\n",
        "image_folder_train = 'data/train'\n",
        "train_data = pd.read_csv(data_train_path, sep=';')\n",
        "train_data['ImagePath'] = train_data['NameofFile'].apply(lambda x: os.path.join(image_folder_train, x))\n",
        "\n",
        "train_data"
      ],
      "id": "ada86f07"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "noteable": {
          "output_collection_id": "c836a117-55f1-4078-9631-5ad038be5f9c"
        },
        "ExecuteTime": {
          "end_time": "2023-06-29T17:41:28.301423+00:00",
          "start_time": "2023-06-29T17:41:28.093421+00:00"
        }
      },
      "outputs": [],
      "source": [
        "def enhance_brightness_contrast_with_clahe(image_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Calculate the mean brightness of the image\n",
        "    mean_brightness = np.mean(gray)\n",
        "    # If the image has low brightness, enhance contrast\n",
        "    if mean_brightness < 128:\n",
        "        # Convert the image to LAB color space\n",
        "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
        "        # Split the LAB image into L, A, and B channels\n",
        "        l, a, b = cv2.split(lab)\n",
        "        # Apply CLAHE to the L channel\n",
        "        clahe = cv2.createCLAHE(clipLimit=10.0, tileGridSize=(8, 8))\n",
        "        cl = clahe.apply(l)\n",
        "        limg = cv2.merge((cl, a, b))\n",
        "        # Convert back to BGR color space\n",
        "        enhanced_image = cv2.cvtColor(limg, cv2.COLOR_Lab2BGR)\n",
        "        return enhanced_image\n",
        "    else:\n",
        "        # Enhance contrast using histogram equalization\n",
        "        gray_equalized = cv2.equalizeHist(gray)\n",
        "        # Convert back to BGR color space\n",
        "        enhanced_image = cv2.cvtColor(gray_equalized, cv2.COLOR_GRAY2BGR)\n",
        "        return enhanced_image"
      ],
      "id": "ac30e9d3"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "noteable": {
          "output_collection_id": "c4954ced-b39c-4018-949e-2e218198d413"
        },
        "ExecuteTime": {
          "end_time": "2023-06-29T17:47:40.002577+00:00",
          "start_time": "2023-06-29T17:47:39.845928+00:00"
        }
      },
      "outputs": [],
      "source": "def denoise_image(image):\n    # Apply Non-Local Means Denoising\n    image = cv2.imread(image_path)\n    # Apply Non-Local Means Denoising\n    return cv2.fastNlMeansDenoising(image, None, 30, 7, 50)",
      "id": "c2716cd2"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "noteable": {
          "output_collection_id": "607c9151-4359-428f-9184-e4dc11c77d40"
        },
        "ExecuteTime": {
          "end_time": "2023-06-29T17:41:32.905046+00:00",
          "start_time": "2023-06-29T17:41:32.735571+00:00"
        }
      },
      "outputs": [],
      "source": "from scipy.signal import convolve2d\n\ndef wiener_deconvolution(image_path, kernel_size, sigma):\n    image = cv2.imread(image_path)\n    kernel = np.ones((kernel_size, kernel_size), np.float32) / (kernel_size ** 2)\n    deblurred_image = cv2.filter2D(image, -1, kernel)\n    return deblurred_image\n",
      "id": "e5812cda"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "noteable": {
          "output_collection_id": "59583a12-5cde-4cc0-a704-b57073418e70"
        },
        "ExecuteTime": {
          "end_time": "2023-06-29T17:41:35.391958+00:00",
          "start_time": "2023-06-29T17:41:35.234486+00:00"
        }
      },
      "outputs": [],
      "source": [
        "def sharpen_image(image, iterations=5):\n",
        "    # Apply the Unsharp Mask filter\n",
        "    blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
        "    sharpened = cv2.addWeighted(image, 1.5, blurred, -0.5, 0)\n",
        "    \n",
        "    # Apply multiple iterations of sharpening\n",
        "    for _ in range(iterations - 1):\n",
        "        sharpened = cv2.addWeighted(sharpened, 1.5, blurred, -0.5, 0)\n",
        "    \n",
        "    return sharpened"
      ],
      "id": "14e8d912"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "noteable": {
          "output_collection_id": "a3e528bf-b4b3-4958-86a3-572631e38da8"
        },
        "ExecuteTime": {
          "end_time": "2023-06-29T17:41:41.575180+00:00",
          "start_time": "2023-06-29T17:41:37.746353+00:00"
        }
      },
      "outputs": [],
      "source": [
        "for image_path in train_data['ImagePath']:\n",
        "    # Enhance brightness and contrast\n",
        "    enhanced_image = enhance_brightness_contrast_with_clahe(image_path)\n",
        "    # Convert to grayscale\n",
        "    gray_image = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2GRAY)\n",
        "    # Denoise the image\n",
        "    resized_image = cv2.resize(gray_image, (300,100))\n",
        "    sharpened_image = sharpen_image(resized_image)\n",
        "    # # Define the kernel for deblurring\n",
        "    # # Deblur the image\n",
        "    # denoised_image = denoise_image(image_path)\n",
        "    # #save the image\n",
        "    cv2.imwrite(image_path, sharpened_image)\n"
      ],
      "id": "c6065e84"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "noteable": {
          "output_collection_id": "cec8a4e2-2684-49a5-bf50-89915aab6538"
        },
        "ExecuteTime": {
          "end_time": "2023-06-29T17:56:48.478203+00:00",
          "start_time": "2023-06-29T17:47:55.446187+00:00"
        }
      },
      "outputs": [],
      "source": "for image_path in train_data['ImagePath']:\n    denoised_image=denoise_image(image)\n    cv2.imwrite(image_path, denoised_image)",
      "id": "1f43b259"
    },
    {
      "id": "c0b29294-ec48-4a7a-abad-58dfa0db05f2",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "24c3978b-e544-47af-be8e-0ac56e83d196"
        },
        "ExecuteTime": {
          "end_time": "2023-06-29T18:27:22.717965+00:00",
          "start_time": "2023-06-29T18:27:22.546141+00:00"
        }
      },
      "execution_count": null,
      "source": "import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef sharpen_and_denoise_image(image_path):\n    # Read the image\n    image = cv2.imread(image_path)\n\n\n    # Sharpen the image (use a stronger kernel)\n    kernel = np.array([[0, -2, 0], [-2, 9, -2], [0, -2, 0]])\n    sharpened_image = cv2.filter2D(image, -1, kernel)\n\n    # Convert the image from BGR to RGB\n    sharpened_image = cv2.cvtColor(sharpened_image, cv2.COLOR_BGR2RGB)\n\n   # Save the processed image back to the original file\n    cv2.imwrite(image_path, sharpened_image)\n\n# Process the first five images\nfor image_path in train_data['ImagePath'][5:10]:\n    sharpen_and_denoise_image(image_path)\n    \n",
      "outputs": []
    },
    {
      "id": "f80329c7-d93b-4c3d-b923-435fa3a80070",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "99a1be50-e5f7-4009-8203-7b53f2dd95d3"
        },
        "ExecuteTime": {
          "end_time": "2023-06-29T18:29:48.713732+00:00",
          "start_time": "2023-06-29T18:29:46.656775+00:00"
        }
      },
      "execution_count": null,
      "source": "def draw_license_plate_box(image_path):\n    # Read the image\n    image = cv2.imread(image_path)\n\n    # Convert the image to grayscale\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Use thresholding to highlight the license plate\n    _, thresh = cv2.threshold(gray, 60, 255, cv2.THRESH_BINARY)\n\n    # Find contours in the thresholded image\n    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n    # Draw bounding box around the detected license plate\n    for contour in contours:\n        x, y, w, h = cv2.boundingRect(contour)\n        # Filter out very small and very large boxes\n        if 1000 > w * h > 100:\n            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n\n    # Convert the image from BGR to RGB\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    # Display the image\n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()\n\n# Process the first five images\nfor image_path in train_data['ImagePath'][:10]:\n    draw_license_plate_box(image_path)",
      "outputs": []
    },
    {
      "id": "411eff29-bbf2-451b-bb14-445db554c9d1",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "40a444fb-3778-45e1-848f-b4213ca5f7b6"
        },
        "ExecuteTime": {
          "end_time": "2023-06-29T18:58:29.551049+00:00",
          "start_time": "2023-06-29T18:58:23.546825+00:00"
        }
      },
      "execution_count": null,
      "source": "!pip install easyocr\n",
      "outputs": []
    },
    {
      "id": "e4f3ebd9-ad76-4868-895b-e3bc6704ec11",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "173f8d2d-4f2d-48a7-bf61-9626989c8b95"
        },
        "ExecuteTime": {
          "end_time": "2023-06-29T19:10:39.397080+00:00",
          "start_time": "2023-06-29T19:10:23.546476+00:00"
        }
      },
      "execution_count": null,
      "source": "import easyocr\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Initialize the easyocr reader\nreader = easyocr.Reader(lang_list=['en'])\n\ndef recognize_license_plate(image_path):\n    # Read the image\n    image = cv2.imread(image_path)\n    \n    # Convert the image from BGR to RGB\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    # Use easyocr to recognize text\n    results = reader.readtext(image)\n\n    # Draw the bounding boxes on the image\n    for (bbox, text, prob) in results:\n        # Unpack the bounding box\n        (top_left, top_right, bottom_right, bottom_left) = bbox\n        top_left = tuple(map(int, top_left))\n        bottom_right = tuple(map(int, bottom_right))\n        \n        # Draw the bounding box and text\n        cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n        cv2.putText(image, text, (top_left[0], top_left[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n        \n        # Print the recognized text\n        print(f\"Recognized text: {text}\")\n\n    # Convert the image from RGB to BGR\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    \n    # Display the image\n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()\n\n# Process the first five images\nfor image_path in train_data['ImagePath'][:5]:\n    recognize_license_plate(image_path)\n",
      "outputs": []
    },
    {
      "id": "356752df-9a58-4f06-be40-8d44f4a234af",
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "execution_count": null,
      "source": "",
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "noteable": {
      "last_transaction_id": "58065095-8c3c-4b86-b7f3-7c09d6898c7c"
    },
    "selected_hardware_size": "small"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}